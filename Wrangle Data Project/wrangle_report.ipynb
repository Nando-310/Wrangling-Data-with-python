{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reporting: wragle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we wrangeled data from the Twitter weratedogs page in order to clean and analyze. We were able to successfuly wrangle the data from several sources including the json file, the predictions html, and the twitter api. Although I had a bit of a struggle getting the information from the Twitter API I was able to manage with out the proper channel. In gathering our data I was able to indentify and clean the data set using tools such as extract to aquire the appropriate information from the Text column to use in our rating_numerator. While extracting from the Text column i had some fun working with Regular Expressions to dial in on what exactly was to be extracted from the Text Column. We noticed many redundant columns which were removed. Also we removed rows with NAn values. There was also an issue with some datatypes that we corrected to the appropriate type. Also we made some changes to better analyze our data such as fixing the rating issues where some ratings went past the normal rating. Once we were able to clean our data we were better able to see the information and process it. After all the cleaning and tidying up we merged all of the data into one dataset and saved it to a new csv file. overall this was a great project to focus on wrangling data and using tools to make it tidy and easier to work with the data. Working with Data and properly cleaning it helps analyst better understand the data and create visuals with the appropriate information. From the 'twitter_archive_master.csv' we were able to gain some fun insights on the WeRateDogs twitter page. Some of the most common used names for dogs were Loki and Sampson. The Entire project was done with Jupyter note books and it was a great experience as my first Data Wrangling job."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
